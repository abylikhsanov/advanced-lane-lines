{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob # To import all the calibration images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calibrate():\n",
    "\n",
    "    objp = np.zeros((6*9,3), np.float32) \n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('/Users/abylikhsanov1/AI/carnd/term1/advanced-lane-lines/camera_cal/calibration*.jpg') # Please update if needed\n",
    "    for fname in images:\n",
    "        image = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None) # Finding any distorted pixel locations\n",
    "        if ret is True: # If we found any, we shall append the coordinates and the pixels itself\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            cv2.drawChessboardCorners(image, (9,6), corners, ret)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    %matplotlib inline\n",
    "    #img = cv2.imread('test_images/straight_lines1.jpg') # Now, let's undistort our first road image\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    # Calibrating and removing the distortion\n",
    "    img_size = (img.shape[1],img.shape[0]) # We are making img_size[0] as x axis values and [1] as y axis\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints,img_size,None,None) # Calibration, moving imgpoints towards the coordinate\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(dst)\n",
    "    ax2.set_title('Undistorted Image', fontsize=30)\n",
    "\n",
    "    \n",
    "    combined_binary = gradient(dst)\n",
    "    warped = warp(combined_binary)\n",
    "    result,left_fitx,right_fitx = fit(warped)\n",
    "    final = unwarp(result,img,left_fitx,right_fitx)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Calculates the directional gradient\n",
    "    # Apply threshold\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(img,cv2.CV_64F,1,0)\n",
    "    elif orient == 'y':\n",
    "        sobel = cv2.Sobel(img,cv2.CV_64F,0,1)\n",
    "    sobel_abs = np.absolute(sobel)\n",
    "    sobel_bin = np.uint8((255*sobel_abs/np.max(sobel_abs)))\n",
    "    grad_binary = np.zeros_like(sobel_bin)\n",
    "    grad_binary[(sobel_bin>=thresh[0])&(sobel_bin<=thresh[1])] = 1\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Calculates the gradient magnitude\n",
    "    # Apply threshold\n",
    "    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0)\n",
    "    sobely = cv2.Sobel(img,cv2.CV_64F,0,1)\n",
    "    sobel_abs = np.absolute(sobelx+sobely)\n",
    "    sobel_bin = np.uint8((255*sobel_abs/np.max(sobel_abs)))\n",
    "    mag_binary = np.zeros_like(sobel_bin)\n",
    "    mag_binary[(sobel_bin>=mag_thresh[0])&(sobel_bin<=mag_thresh[1])] = 1\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Calculates the gradient direction\n",
    "    # Apply threshold\n",
    "    sobelx = np.absolute(cv2.Sobel(img,cv2.CV_64F,1,0))\n",
    "    sobely = np.absolute(cv2.Sobel(img,cv2.CV_64F,0,1))\n",
    "    sobel_arctan = np.uint8(np.arctan(sobely,sobelx))\n",
    "    dir_binary = np.zeros_like(sobel_arctan)\n",
    "    dir_binary[(sobel_arctan>=thresh[0])&(sobel_arctan<=thresh[1])] = 1\n",
    "    return dir_binary\n",
    "\n",
    "k_size = 7 # To make our image smoother, I have concluded, that this Kernel size is optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(dst):\n",
    "    gray = cv2.cvtColor(dst,cv2.COLOR_RGB2GRAY)\n",
    "    hls = cv2.cvtColor(dst,cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    # Sobel X on gray:\n",
    "    sobel_gray = abs_sobel_thresh(gray, orient='x', sobel_kernel=k_size, thresh=(20, 200))\n",
    "\n",
    "    # Sobel X on S (HLS):\n",
    "    sobel_s = abs_sobel_thresh(hls[:,:,2], orient='x', sobel_kernel=k_size, thresh=(180, 255))\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sobel_gray)\n",
    "    combined_binary[(sobel_s == 1) | (sobel_gray == 1)] = 1\n",
    "\n",
    "    # Plotting thresholded images\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.set_title('Stacked thresholds')\n",
    "    ax1.imshow(dst)\n",
    "\n",
    "    ax2.set_title('Combined S channel and gradient thresholds')\n",
    "    ax2.imshow(combined_binary, cmap='gray')\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Time to warp the image\n",
    "def warp(combined_binary):\n",
    "    img_size = (combined_binary.shape[1],combined_binary.shape[0])\n",
    "    bottom_left = [320,720] \n",
    "    bottom_right = [920, 720]\n",
    "    top_left = [320, 1]\n",
    "    top_right = [920, 1]\n",
    "    src = np.float32([[256,688],[544,492],[752,492],[1044,688]])\n",
    "    dest = np.float32([bottom_left,top_left,top_right,bottom_right])\n",
    "    M = cv2.getPerspectiveTransform(src,dest)\n",
    "    warped = cv2.warpPerspective(combined_binary,M,img_size)\n",
    "# Plotting warped and non images\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.set_title('Combined S channel and gradient thresholds')\n",
    "    ax1.imshow(combined_binary,cmap='gray')\n",
    "\n",
    "    ax2.set_title('Warped image')\n",
    "    ax2.imshow(warped, cmap='gray')\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    # Viewing the most dense pixel region (sum of 1 on the X scale)\n",
    "histogram = np.sum(warped[int(warped.shape[0]/2):,:],axis=0)\n",
    "plt.plot(histogram)\n",
    "out_img = warped\n",
    "\n",
    "    #In order to fit the polynomial for the lines, I will divide the image by 2 on x axis, to seperate left and right lanes\n",
    "midpoint = int(histogram.shape[0]/2)\n",
    "left_side = np.argmax(histogram[:midpoint]) # Getting the most dense pixel region at x axis, argmax returns the index\n",
    "right_side = np.argmax(histogram[midpoint:]) + midpoint # Getting the most dense pixel region at x axis right side\n",
    "# As the maximum Y value is 720, I will choose to divide it to 9 windows\n",
    "windows = 9\n",
    "\n",
    "# Set height of windows\n",
    "window_height = np.int(warped.shape[0]/windows) # In this code, this is int size of 80 (80 pixels)\n",
    "\n",
    "# Identify the x and y positions of all nonzero pixels in the image\n",
    "nonzero = warped.nonzero() # Pixel locations where pixel is 1, [1] = x, [0] = y\n",
    "nonzeroy = np.array(nonzero[0]) \n",
    "nonzerox = np.array(nonzero[1])\n",
    "\n",
    "# Current positions to be updated for each window\n",
    "leftx_current = left_side \n",
    "rightx_current = right_side\n",
    "\n",
    "# Set the width of the windows +/- margin\n",
    "margin = 100\n",
    "# Set minimum number of pixels found to recenter window\n",
    "minpix = 50\n",
    "# Create empty lists to receive left and right lane pixel indices\n",
    "left_lane_inds = []\n",
    "right_lane_inds = []\n",
    "\n",
    "# Step through the windows one by one\n",
    "for window in range(windows): # Looping in 9 steps\n",
    "    # Identify window boundaries in x and y (and right and left)\n",
    "    win_y_low = warped.shape[0] - (window+1)*window_height # Loop 1, 0+1 * 80 = 80 px\n",
    "    win_y_high = warped.shape[0] - window*window_height # Loop 1, 0 px, this is a top value, as y values are from the top to the bottom\n",
    "    win_xleft_low = left_side - margin # Setting the square boundaries, from the current found lane piece\n",
    "    win_xleft_high = left_side + margin\n",
    "    win_xright_low = right_side - margin\n",
    "    win_xright_high = right_side + margin\n",
    "    # Draw the windows on the visualization image\n",
    "    cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "    cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "    # Identify the nonzero pixels in x and y within the window\n",
    "    left_nzero_values = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "    (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]  # Getting the pixel locations, where pixel>1\n",
    "    right_nzero_values = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "    (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "    # Append these indices to the lists\n",
    "    left_lane_inds.append(left_nzero_values) # Left_lane_inds is the list of pixel locations in that margin box\n",
    "    right_lane_inds.append(right_nzero_values)\n",
    "    # If you found > minpix pixels, recenter next window on their mean position\n",
    "    if len(left_nzero_values) > minpix:\n",
    "        leftx_current = np.int(np.mean(nonzerox[left_nzero_values])) # Enhance: Try to get the argmax of np.sum of the location\n",
    "    if right_nzero_values.size > minpix:        \n",
    "        rightx_current = np.int(np.mean(nonzerox[right_nzero_values])) # For all the x values with pixels>1, we get the mean of that\n",
    "\n",
    "\n",
    "# Concatenate the arrays of indices\n",
    "left_lane_inds = np.concatenate(left_lane_inds)\n",
    "right_lane_inds = np.concatenate(right_lane_inds)\n",
    "# Extract left and right line pixel positions\n",
    "leftx = nonzerox[left_lane_inds] # Get the\n",
    "lefty = nonzeroy[left_lane_inds] \n",
    "rightx = nonzerox[right_lane_inds]\n",
    "righty = nonzeroy[right_lane_inds]\n",
    "# Fit a second order polynomial to each\n",
    "left_fit = np.polyfit(lefty, leftx, 2)\n",
    "right_fit = np.polyfit(righty, rightx, 2)\n",
    "out_img = np.dstack((warped, warped, warped))*255\n",
    "window_img = np.zeros_like(out_img) # Getting the blank image to display the curves\n",
    "# Color in left and right line pixels\n",
    "out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0] ) # All the y values\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "# Generate a polygon to illustrate the search window area\n",
    "# And recast the x and y points into usable format for cv2.fillPoly()\n",
    "left_line_window1 = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+(right_fitx-left_fitx),ploty])))])\n",
    "left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "\n",
    "result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "plt.imshow(result)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unwarp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottom_left = [left_fitx[0],result.shape[0]] \n",
    "bottom_right = [right_fitx[0], result.shape[0]]\n",
    "top_left = [left_fitx[-1], 0]\n",
    "top_right = [right_fitx[-1], 0]\n",
    "dest = np.float32([[256,688],[544,492],[752,492],[1044,688]])\n",
    "src = np.float32([bottom_left,top_left,top_right,bottom_right])\n",
    "img_size = (img.shape[1],img.shape[0])\n",
    "M = cv2.getPerspectiveTransform(src,dest)\n",
    "result_unwarp = cv2.warpPerspective(result,M,img_size)\n",
    "# Plotting warped and non images\n",
    "if len(img.shape) > 2:\n",
    "    channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "    ignore_mask_color = (255,) * channel_count\n",
    "else:\n",
    "    ignore_mask_color = 255\n",
    "\n",
    "mask = np.zeros_like(result)\n",
    "vertices = np.array([[[256,688],[544,492],[752,492],[1044,688]]],dtype=np.int32)\n",
    "cv2.fillPoly(mask, vertices,ignore_mask_color)\n",
    "#returning the image only where mask pixels are nonzero\n",
    "masked_image = cv2.bitwise_and(result_unwarp, mask)\n",
    "final = cv2.addWeighted(img, 1, masked_image, 1, 1)\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(20,10))\n",
    "\n",
    "ax1.set_title('Warped image')\n",
    "ax1.imshow(final)\n",
    "cv2.imwrite( \"output_images/straight_lines1.jpg\", cv2.cvtColor(final,cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
