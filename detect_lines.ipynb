{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calibrate():\n",
    "    objp = np.zeros((6*9,3), np.float32) \n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('/Users/abylikhsanov1/AI/carnd/term1/advanced-lane-lines/camera_cal/calibration*.jpg')\n",
    "    for image in images:\n",
    "        img = cv2.imread(image)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        ret,corners = cv2.findChessboardCorners(gray,(9,6),None)\n",
    "        if ret is True:\n",
    "            imgpoints.append(corners)\n",
    "            objpoints.append(objp)\n",
    "            cv2.drawChessboardCorners(gray,(9,6),corners,ret)\n",
    "    \n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints,img_size,None,None)\n",
    "    return mtx,dist\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    %matplotlib inline\n",
    "    global mtx\n",
    "    global dist\n",
    "    undistorted = cv2.undistort(img,mtx,dist,None,mtx)\n",
    "    masked_image = threshold(undistorted)\n",
    "    warped,M_inv = warp(masked_image)\n",
    "    result,left_fitx,right_fitx,string = fit(warped)\n",
    "    final = unwarp(result,left_fitx,right_fitx,M_inv,undistorted,string)\n",
    "    return final\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sobel(img,orient='x',ksize=3,thresh=(0,255)):\n",
    "    if orient is 'x':\n",
    "        sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=ksize)\n",
    "    elif orient is 'y':\n",
    "        sobelx = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=ksize)\n",
    "    sobel_abs = np.absolute(sobelx)\n",
    "    sobel_binary = np.uint8(255*sobel_abs/np.max(sobel_abs))\n",
    "    empty = np.zeros_like(sobel_binary)\n",
    "    empty[(sobel_binary >= thresh[0]) & (sobel_binary <= thresh[1])] = 1\n",
    "    return empty\n",
    "\n",
    "def magnitude(img,ksize=3,thresh=(0,255)):\n",
    "    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=ksize)\n",
    "    sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=ksize)\n",
    "    sobel_abs = np.absolute(sobelx+sobely)\n",
    "    sobel_bin = np.uint8(255*sobel_abs/np.max(sobel_abs))\n",
    "    empty = np.zeros_like(sobel_bin)\n",
    "    empty[(sobel_bin >= thresh[0]) & (sobel_bin<= thresh[1])] = 1\n",
    "    return empty\n",
    "\n",
    "def direction(img,ksize=3,thresh=(0,255)):\n",
    "    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=ksize)\n",
    "    sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=ksize)\n",
    "    sobel_bin = np.arctan(np.absolute(sobelx),np.absolute(sobely))\n",
    "    empty = np.zeros_like(sobel_bin)\n",
    "    empty[(sobel_bin >= thresh[0]) & (sobel_bin <= thresh[1])] = 1\n",
    "    return empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threshold(undistorted):\n",
    "    hls = cv2.cvtColor(undistorted,cv2.COLOR_RGB2HLS)\n",
    "    gray = cv2.cvtColor(undistorted,cv2.COLOR_RGB2GRAY)\n",
    "    luv = cv2.cvtColor(undistorted,cv2.COLOR_RGB2LUV)\n",
    "    l_thresh = (60, 255) #(170,255)\n",
    "    s_thresh=(40, 100) # (8,120)\n",
    "    R_thresh = (210, 255)\n",
    "    G_thresh = (195, 255)\n",
    "\n",
    "\n",
    "    r_mag = sobel(undistorted[:,:,0],ksize=3,thresh=R_thresh)\n",
    "    g_mag = sobel(undistorted[:,:,1],ksize=3,thresh=G_thresh)\n",
    "    s_mag = sobel(hls[:,:,2],ksize=9,thresh=s_thresh)\n",
    "    l_mag = magnitude(hls[:,:,1],ksize=9,thresh=l_thresh)\n",
    "    combined_binary = np.zeros_like(r_mag)\n",
    "    combined_binary[((r_mag==1) & (g_mag==1))|(s_mag==1)|(l_mag==1)] = 1\n",
    "\n",
    "    if len(combined_binary.shape) > 2:\n",
    "        channel_count = combined_binary.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    vertices = np.int32([[[190,700],[570,450],[800,450],[1200,700]]])\n",
    "    mask = np.zeros_like(combined_binary)\n",
    "    cv2.fillPoly(mask, vertices,ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(combined_binary, mask)\n",
    "    fig,(ax1) = plt.subplots(1,1,figsize=(10,5))\n",
    "    ax1.imshow(masked_image,cmap='gray')\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def warp(masked_image):\n",
    "    img_size = (masked_image.shape[1],masked_image.shape[0])\n",
    "    offset = 200\n",
    "    x1 = 200\n",
    "    x2 = 1100\n",
    "    src = np.float32([[x1,720], [599,446], [680,446], [x2,720]])\n",
    "    dest = np.float32([[x1+offset,720], [x1+offset,0], [x2-offset,0], [x2-offset,720]])\n",
    "    M = cv2.getPerspectiveTransform(src,dest)\n",
    "    M_inv = cv2.getPerspectiveTransform(dest,src)\n",
    "    warped = cv2.warpPerspective(masked_image,M,img_size)\n",
    "    return warped,M_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(warped):\n",
    "    histogram = np.sum(warped[int(warped.shape[0]/2):,:],axis=0)\n",
    "    out_img = warped\n",
    "    #fig,(ax1) = plt.subplots(1,1,figsize=(10,5))\n",
    "    #ax1.plot(histogram)\n",
    "\n",
    "    #In order to fit the polynomial for the lines, I will divide the image by 2 on x axis, to seperate left and right lanes\n",
    "    midpoint = int(histogram.shape[0]/2)\n",
    "    left_side = np.argmax(histogram[:midpoint]) # Getting the most dense pixel region at x axis, argmax returns the index\n",
    "    right_side = np.argmax(histogram[850:1100]) + midpoint# Getting the most dense pixel region at x axis right side\n",
    "    if(right_side-left_side<500):\n",
    "        right_side = left_side+500\n",
    "    # As the maximum Y value is 720, I will choose to divide it to 9 windows\n",
    "    windows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(warped.shape[0]/windows) # In this code, this is int size of 80 (80 pixels)\n",
    "\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = warped.nonzero() # Pixel locations where pixel is 1, [1] = x, [0] = y\n",
    "    nonzeroy = np.array(nonzero[0]) \n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = left_side \n",
    "    rightx_current = right_side\n",
    "\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(windows): # Looping in 9 steps\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = warped.shape[0] - (window+1)*window_height # Loop 1, 0+1 * 80 = 80 px\n",
    "        win_y_high = warped.shape[0] - window*window_height # Loop 1, 0 px, this is a top value, as y values are from the top to the bottom\n",
    "        win_xleft_low = left_side - margin # Setting the square boundaries, from the current found lane piece\n",
    "        win_xleft_high = left_side + margin\n",
    "        win_xright_low = right_side - margin\n",
    "        win_xright_high = right_side + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
    "        (0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
    "        (0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        left_nzero_values = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]  # Getting the pixel locations, where pixel>1\n",
    "        right_nzero_values = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(left_nzero_values) # Left_lane_inds is the list of pixel locations in that margin box\n",
    "        right_lane_inds.append(right_nzero_values)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(left_nzero_values) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[left_nzero_values])) # Enhance: Try to get the argmax of np.sum of the location\n",
    "        if right_nzero_values.size > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[right_nzero_values])) # For all the x values with pixels>1, we get the mean of that\n",
    "\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds] # Get the\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    out_img = np.dstack((warped, warped, warped))*255\n",
    "    window_img = np.zeros_like(out_img) # Getting the blank image to display the curves\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0]) # All the y values\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+(right_fitx-left_fitx),ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    \n",
    "    # Measuring the curve radius\n",
    "    ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "    quadratic_coeff = 3e-4\n",
    "    left_fit_try = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit_try = np.polyfit(righty, rightx, 2)\n",
    "    leftx = np.array([200 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) \n",
    "                              for y in ploty])\n",
    "    rightx = np.array([900 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) \n",
    "                                for y in ploty])\n",
    "\n",
    "    leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    # Fit a second order polynomial to pixel positions in each fake lane line\n",
    "    left_fit_c = np.polyfit(ploty, leftx, 2)\n",
    "    left_fitx_c = left_fit_try[0]*ploty**2 + left_fit_try[1]*ploty + left_fit_try[2]\n",
    "    right_fit_c = np.polyfit(ploty, rightx, 2)\n",
    "    right_fitx_c = right_fit_try[0]*ploty**2 + right_fit_try[1]*ploty + right_fit_try[2]\n",
    "\n",
    "    y_eval = np.max(ploty)\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "# Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "# Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    string = str(left_curverad-right_curverad)\n",
    "    #fig,(ax1) = plt.subplots(1,1,figsize=(10,5))\n",
    "    #ax1.imshow(result)\n",
    "    #ax1.plot(left_fitx,ploty,color='yellow')\n",
    "    #ax1.plot(right_fitx,ploty,color='yellow')\n",
    "    return result,left_fitx,right_fitx,string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unwarp(result,left_fitx,right_fitx,M_inv,undistorted,string):\n",
    "    warp_zero = np.zeros_like(result)\n",
    "    img_size = (result.shape[1],result.shape[0])\n",
    "    ploty = np.linspace(0, result.shape[0]-1, result.shape[0])\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.fillPoly(warp_zero, np.int_([pts]), (255,0,0))\n",
    "\n",
    "    unwarped = cv2.warpPerspective(result,M_inv,img_size)\n",
    "\n",
    "    newwarp = cv2.warpPerspective(warp_zero, M_inv, (result.shape[1], result.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    final = cv2.addWeighted(undistorted, 1, newwarp, 0.3, 0)\n",
    "    cv2.putText(final,string,(600,100),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_videos/project_video1.mp4\n",
      "[MoviePy] Writing video output_videos/project_video1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 25/26 [00:05<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_videos/project_video1.mp4 \n",
      "\n",
      "CPU times: user 7.21 s, sys: 1.04 s, total: 8.25 s\n",
      "Wall time: 6.1 s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAEzCAYAAABZt4vXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHHlJREFUeJzt3W/sZNV93/H3t6yB2Km9QAqiu+sC8sqxG8VAV3hTR5UL\nqQPE8vLASFiuWFGkfeK2dhMphvqBlT6q1SrEyC3tChwvkYNNiR1WVutktSZKn0C8/hOMvSb7s5Oy\nv+yGdbWwToJkh/rbB3MGhtk7M2fmN3/uzLxf0k8z98ydmTP3d+fez5xz7r2RmUiSJNX4e4uugCRJ\nWh4GB0mSVM3gIEmSqhkcJElSNYODJEmqZnCQJEnVZhIcIuLmiHg2IjYi4p5ZvIckSZq/mPZ5HCLi\nAuDPgH8BbAJfBT6Qmd+Z6htJkqS5m0WLww3ARmZ+PzN/DHwO2DeD95EkSXM2i+CwAzjZM71ZyiRJ\n0pLbNoPXjIay8/pDIuIAcKBM/pMZ1EOSJI0hM5v24a8xi+CwCezqmd4JnOqfKTMPAgcBIsILZkiS\ntARm0VXxVWB3RFwdERcCdwCHZ/A+kiRpzqbe4pCZL0fEvwb+ALgA+HRmfnva7yNJkuZv6odjTlQJ\nuyokSVq4mjEOnjlSkiRVMzhIkqRqBgdJklTN4CBJkqoZHCRJUjWDgyRJqmZwkCRJ1QwOkiSpmsFB\nkiRVMzhIkqRqBgdJklTN4CBJkqoZHCRJUjWDgyRJqmZwkCRJ1QwOkiSpmsFBkiRVMzhIkqRqBgdJ\nklTN4CBJkqoZHCRJUjWDgyRJqmZwkCRJ1QwOkiSpmsFBkiRVMzhIkqRqBgdJklTN4CBJkqoZHCRJ\nUrWRwSEiPh0RZyLimZ6ySyPiSEScKLeXlPKIiPsjYiMino6I62dZeUmSNF81LQ6fAW7uK7sHOJqZ\nu4GjZRrgFmB3+TsAPDCdakqSpDYYGRwy84+Bs33F+4BD5f4h4Lae8oez40lge0RcOa3KSpKkxZp0\njMMVmXkaoNxeXsp3ACd75tssZZIkaQVsm/LrRUNZNs4YcYBOd4YkSVoSk7Y4PN/tgii3Z0r5JrCr\nZ76dwKmmF8jMg5m5JzP3TFgHSZI0Z5MGh8PA/nJ/P/B4T/md5eiKvcC5bpeGJElafpHZ2JPw6gwR\njwDvBn4GeB74OPD7wKPAm4HngNsz82xEBPApOkdhvATclZnHRlYiYnglJEnSzGVm05CD1xgZHObB\n4CBJ0uLVBAfPHClJkqoZHCRJUjWDgyRJqmZwkCRJ1QwOkiSpmsFBkiRVMzhIkqRqBgdJklTN4CBJ\nkqoZHCRJUjWDgyRJqmZwkCRJ1QwOkiSpmsFBkiRVMzhIkqRqBgdJklTN4CBJkqoZHCRJUjWDgyRJ\nqmZwkCRJ1QwOkiSpmsFBkiRVMzhIkqRqBgdJklTN4CBJkqoZHCRJUjWDgyRJqmZwkCRJ1QwOkiSp\n2sjgEBG7IuKJiDgeEd+OiA+X8ksj4khEnCi3l5TyiIj7I2IjIp6OiOtn/SEkSdJ81LQ4vAz8Wma+\nDdgLfCgi3g7cAxzNzN3A0TINcAuwu/wdAB6Yeq0lSdJCjAwOmXk6M79e7v81cBzYAewDDpXZDgG3\nlfv7gIez40lge0RcOfWaS5KkuRtrjENEXAVcBzwFXJGZp6ETLoDLy2w7gJM9T9ssZZIkacltq50x\nIn4a+D3gI5n5w4gYOGtDWTa83gE6XRmSJGlJVLU4RMTr6ISGz2bmF0rx890uiHJ7ppRvArt6nr4T\nONX/mpl5MDP3ZOaeSSsvSZLmq+aoigAeAo5n5m/2PHQY2F/u7wce7ym/sxxdsRc41+3SkCRJyy0y\nz+tFeO0MEb8I/G/gW8BPSvG/pzPO4VHgzcBzwO2ZebYEjU8BNwMvAXdl5rER7zG8EpIkaeYyc+A4\nhK6RwWEeDA6SJC1eTXDwzJGSJKmawUGSJFUzOEiSpGoGB0mSVM3gIEmSqhkcJElSNYODJEmqZnCQ\nJEnVDA6SJKmawUGSJFUzOEiSpGoGB0mSVM3gIEmSqhkcJElSNYODJEmqZnCQJEnVDA6SJKmawUGS\nJFUzOEiSpGoGB0mSVM3gIEmSqhkcJElSNYODJEmqZnCQJEnVDA6SJKmawUGSJFUzOEiSpGoGB0mS\nVG1kcIiIiyPiTyLiTyPi2xHxG6X86oh4KiJORMTnI+LCUn5Rmd4oj181248gSZLmpabF4UfAjZn5\nDuBa4OaI2At8ArgvM3cDLwB3l/nvBl7IzLcA95X5JEnSChgZHLLjb8rk68pfAjcCj5XyQ8Bt5f6+\nMk15/KaIiKnVWJIkLUzVGIeIuCAivgmcAY4A3wNezMyXyyybwI5yfwdwEqA8fg64bJqVliRJi1EV\nHDLz/2XmtcBO4AbgbU2zldum1oXsL4iIAxFxLCKO1VZWkiQt1lhHVWTmi8AfAXuB7RGxrTy0EzhV\n7m8CuwDK428Czja81sHM3JOZeyaruiRJmreaoyr+QURsL/d/Cvgl4DjwBPD+Mtt+4PFy/3CZpjz+\nlcw8r8VBkiQtnxi1T4+In6cz2PECOkHj0cz8DxFxDfA54FLgG8C/zMwfRcTFwO8A19FpabgjM78/\n4j0MFpIkLVhmjjyYYWRwmAeDgyRJi1cTHDxzpCRJqmZwkCRJ1QwOkiSpmsFBkiRVMzhIkqRqBgdJ\nklTN4CBJkqoZHCRJUjWDgyRJqmZwkCRJ1QwOkiSpmsFBkiRVMzhIkqRqBgdJklTN4CBJkqoZHCRJ\nUjWDgyRJqmZwkCRJ1QwOkiSpmsFBkiRVMzhIkqRqBgdJklTN4CBJkqoZHCRJUjWDgyRJqmZwkCRJ\n1QwOkiSpmsFBkiRVMzhIkqRq1cEhIi6IiG9ExJfK9NUR8VREnIiIz0fEhaX8ojK9UR6/ajZVlyRJ\n8zZOi8OHgeM9058A7svM3cALwN2l/G7ghcx8C3BfmU+SJK2AquAQETuBXwEeLNMB3Ag8VmY5BNxW\n7u8r05THbyrzS5KkJVfb4vBbwK8DPynTlwEvZubLZXoT2FHu7wBOApTHz5X5JUnSkhsZHCLivcCZ\nzPxab3HDrFnxWO/rHoiIYxFxrKqmkiRp4bZVzPMu4H0RcStwMfBGOi0Q2yNiW2lV2AmcKvNvAruA\nzYjYBrwJONv/opl5EDgIEBHnBQtJktQ+I1scMvPezNyZmVcBdwBfycwPAk8A7y+z7QceL/cPl2nK\n41/JTIOBJEkrYCvncfgo8KsRsUFnDMNDpfwh4LJS/qvAPVuroiRJaotoQ2OAXRWSJC1eZo48CtIz\nR0qSpGoGB0mSVM3gIEmSqhkcJElSNYODJEmqZnCQJEnVDA6SJKmawUGSJFUzOEiSpGoGB0mSVM3g\nIEmSqhkcJElSNYODJEmqZnCQJEnVDA6SzpOZZOZrpiUJYNuiKyCpXTKTiHjlPvDKtCTZ4iBpYAtD\nRCxdaOj/LJKmy+AgrbHuTra3hWHZgkK/Za+/1HZ2VUhrqLdFoT88dMuXWfdzde9Lmh5bHKQ1MqiF\nYRV3rr2fcV5dF933satEq8wWB2kNNLUwrIN5B6Lelg5pVRkcpBU2qktCs9W//F32WgV2VUgrqL9/\n353WYvR2A9kaoVVhcJBWRG8XxKoOelwGw8aMGB60CgwO0hLrH4xnYKizTuM8pGlzjIO0pHp3fAaG\n8bhcpMkZHKQl0zR+QcvDcSdadgYHaQn0h4NBfeXuiJaH/ystK8c4SC3X3yXRLevvknBHJGkeqoJD\nRPxFRHwrIr4ZEcdK2aURcSQiTpTbS0p5RMT9EbEREU9HxPWz/ADSqukd8Nh/Zsd1OetjGziAUmo2\nTovDP8/MazNzT5m+BziambuBo2Ua4BZgd/k7ADwwrcpKq27YURLd6e6tgWF2mq4UKqljK10V+4BD\n5f4h4Lae8oez40lge0RcuYX3kdbCoC6J/jLNnidukgarDQ4J/GFEfC0iDpSyKzLzNEC5vbyU7wBO\n9jx3s5RJatDfouCOqj16TxXt/0TqqD2q4l2ZeSoiLgeORMR3h8zb9LPovG9cCSAHGuaVVl7TURLD\nyrU4/aHBwyi17qpaHDLzVLk9A3wRuAF4vtsFUW7PlNk3gV09T98JnGp4zYOZuadnzIS0FoZ1SXRb\nHBzD0C69LUHrdoVRqd/I4BARb4iIv9+9D7wHeAY4DOwvs+0HHi/3DwN3lqMr9gLnul0a0rprOttj\n02NqJ/9nUl1XxRXAF8uvn23A72bmlyPiq8CjEXE38Bxwe5n/fwK3AhvAS8BdU6+1tISGHSlh8/fy\n6P9/9R/xIq26aENijojFV0KaMscxrL6m82pIyywzR67EnnJamrLawND7mJZT09EWBgitOoODNENe\nU2L19QbD3hN4+T/WqjI4SFMy6gRO/Y9ptXiuB60Lg4M0BaMudW1YWA/+n7UODA7SBPrPJtg0wt7R\n9pJWkcFBGtOgC1H1z2NgkLSKDA7ShBzHIGkdbeXqmNJaaGphaDrtcO/VFCVpVdniIFVoOlMgNB+K\nJ0mrzOAgjdDbgjDsWhP980rSKjI4SD0GDWpsak1oanmQpFVncJCKUYdYdss8zFLSOjM4SD36Wxya\nQoSBQdI6MzhIxagWBkODJHk4pvQahgZNm0fbaNUYHLSWRg127GdoUJeH3mrdRRu+ABGx+EpII9jq\nMBsuV6k9MnPkl9EWB629/jNDav5c9tLycHCk1kLTIZTDLlLVxF/F4/PQVWn1GBy00oYFht5yD8Gc\nrkkCg8tZWg52VWildS9IBecPaus/aqL/eU3lGq67jHuX+yjjzLss7P7SKjM4aC30X9myW9bU4tB/\ndshV26nNit0Sr9V/JlJpVRgctPKadmijAoE7v8GGtdJMutxWbefathar/ta22kNK21J/tYvBQSth\n0HkZBg2AdIOoWWtqzRpkluvjsNce9b4GaDUxOGjpDTuZU/dXsM3G0zPODnHdjTPOY6sGrdvd70D/\ne/j/06Q8AZSWTu/YhGEXpRo04HGZDBo3MK0jEJbhSIZJ6jjpc2A268msl3PTuu6ZUDUJTwCllTNq\ntPqgX1bLvKGcZd2XYblMGgBm/T7j6q/XqHEG45zauqnug8qW4X+udvM8DloKg7ojhp1rYRU2kIM+\nwzx+gS+DaX+uQVdInZZx6jvp+w573iq0wmnxDA5qvWEb8TZ0tS2DVd1B1P7ShvG6IiY9KmIewWDc\n11zV/70Wp6qrIiK2R8RjEfHdiDgeEb8QEZdGxJGIOFFuLynzRkTcHxEbEfF0RFw/24+gVdV0wqam\nx9p26NsieeXGyTUtt3F3uqNaiKbdetH0PaipT+9rSOOqHePwSeDLmfmzwDuA48A9wNHM3A0cLdMA\ntwC7y98B4IGp1lhrof+oiKazP/Z3U/jLavp92OsSRObRlTPt13ed16KMPKoiIt4I/ClwTfbMHBHP\nAu/OzNMRcSXwR5n51oj47+X+I/3zDXmP1d8yqdqwIwmaLPvGs81nXNzqDrVtYyua6tO2Oo6rZv0Z\nNk+b1z/N37SOqrgG+AHw2xHxjYh4MCLeAFzRDQPl9vIy/w7gZM/zN0uZNFTvdQ66073lcP7GzY1d\nu7Xt/7OKYwBqWh6GPd7//HVoYdLW1ASHbcD1wAOZeR3wt7zaLdGkaQ09b02MiAMRcSwijlXVVCuv\ndwPWvd90CNugE9poupb9l7hea5GDNmF9ur3WQU1w2AQ2M/OpMv0YnSDxfOmioNye6Zl/V8/zdwKn\n+l80Mw9m5p7M3DNp5bXaBl1jYhX0D/ps2+eq3cBPe2fgjkVqv5HBITP/CjgZEW8tRTcB3wEOA/tL\n2X7g8XL/MHBnObpiL3Bu2PgGra9BO4mma0y0cee6FcvwWWZ52OJW3lNbM+twNs7J2bScqk45HRHX\nAg8CFwLfB+6iEzoeBd4MPAfcnplno7NmfAq4GXgJuCszh3ZHODhyvQw6KqIpLEzaXO6AL627QYcr\nz/o7Meo7axdYu9UMjvRaFZqrQaPaYXCQ6H2s5vV7uYHSOht1dlWpn8FBrTHuRqttFyka9F7zer9Z\ncoeiZeR6Oxs1wcFTTmumRp2TYdhx5ZOYV2ho4wZrkuDU1s8ijeJ6uzgGB83MoJ1SbzCYtJWg6Re/\nGxKXgZabY5OWg8FBU1fbmtB/0plxAsBWBk5u1bTfe1qv5cZWy851eDnUXqtCGqn3zI/DuiamcVjW\ntHfc43aP1Jzed9w6zMsqjc9Q+3iip9VncNBU1LQyDNqgTLKRGbcff1D5VppGp3XtjHnvvA0Lszfu\nztMdrZaJXRXaspqxDF1N3ROLOuZ7qxdvmgZ3GKtnVBhdxTOijtvVqOVmcNDEaq9iOe0jJ2rq1caN\nV1O9FjlWQ7Ph/1Krzq4KTVVTmBjU8jDOKY3H0bRzbrNhv0xtkVg9q3LqZdfN9WWLgybWFA7acJa6\nYV0nw3bSs67vJGe/XIUdjFRrHt9Dv19bZ3BQlZrBj/3Xm2ibYXVqU33bVBdpXFvZ+Q86RHtahg2U\n7n9/DWZw0EijfqkPuu+XUFpdsx7cOcvtx7J1Z7aNwUEDDTvqoT8YtOWLN69+17Z8Xmmean4QtPm7\n0ea6LRMHR6rRsHECTZfB7j62KP0nmJLaYNUGEPrdEtjioAFqL33d/5x17KJYx8+sOq4XWkW2OGik\nYRel6rZAzHJw0ahfbYv+VTfpZ150vSVpEgYHDd2B9QeCQTvJeQ5kmuf7z3LnPs06G0IkzYvBQcD5\nO56mC1Y17ejaMKagd7xF1zR3pNN4rf6WGUnLa92/xwYHAed3PfSWzUrve01yUaBhJ3KZVt27wWjS\nnf48luUqjLFY9w2xlkvTj5V1YnBYc0077q3uLGvV7uwH1WPZdpaLGP+xLJbtf6n1MGwbuM7rrEdV\nCBjcDTHri1ENe/9hj4360rblV/isTzTTdChsGz63pNVlcNDAC1LNevzCrILJJNeqqDHqENVFmvRQ\n2P5zcmiwNvyfNV/+z5sZHNZc/05jXl+UYWel3OrrzsIkrR6LsJVxGF1t/FzzMK/Dftd1+dboDbIu\np/aKNvzSiIjFV0Kv+bLWfHGb5ql9XtcsgsMybHj669n2+mp2xtkGr/I64negHTJz5D/B4LCiBu3U\nobnJvfaqdKN2+rWPz3qg4FZOyjRJc38TN4KaplHb6mVf39oUHAZ14dXWr02fZVw1wcGuihU1LDQ0\nndSp5hfwsB1z7UWvxu1P76/3tE+a1DS+Y9wN9LJuILRcxlnPBu3w2rxDa0vL21Z+PDRtUyd9zTaz\nxWFFDPslP82VdtjAw0HvP+jxceo1TmtCbYtJk1X6ckuDLPoonEHvv6h6TWP7soxhrYktDmti0M6w\nf2c9jRW4qcWiv3zU87YyMHKc8RNN0+O8lrSqFrnuDzuSZ5J6TWu7Vvu6ow4dr219XWYjTwAVEW+N\niG/2/P0wIj4SEZdGxJGIOFFuLynzR0TcHxEbEfF0RFw/+4+h/h3xoJ37Vg37ko56/f6ukJpR7P0n\npRo0T//rdae7z2v6kzR/vc350/geTmu71ns76HVrfoisw7ZlrK6KiLgA+EvgncCHgLOZ+R8j4h7g\nksz8aETcCvwb4NYy3ycz850jXteuiimb1diAUWMgttIPW2sdvpiStAg1XRXjnnL6JuB7mfl/gH3A\noVJ+CLit3N8HPJwdTwLbI+LKMd9HE+r/pb3V1+q97TXstftbAQb9Nb1mzZ8kbcWw7ZBGG3eMwx3A\nI+X+FZl5GiAzT0fE5aV8B3Cy5zmbpez0Viq67sYZ8DeLLon+boDa50lS27iN2prq4BARFwLvA+4d\nNWtD2Xl7mog4AByofX+dr/a8DL3z1lr1wT2SpMmM0+JwC/D1zHy+TD8fEVeW1oYrgTOlfBPY1fO8\nncCp/hfLzIPAQXCMQ41xRvf2l7vjlyRNyzhjHD7Aq90UAIeB/eX+fuDxnvI7y9EVe4Fz3S4NSZK0\n3KqOqoiI19MZt3BNZp4rZZcBjwJvBp4Dbs/Ms9H5efsp4GbgJeCuzDw24vVtcZAkacFqjqrwzJGS\nJAmYzeGYkiRpjRkcJElSNYODJEmq1paLXP0N8OyiK7FEfgb4v4uuxJJwWY3H5VXPZTUel1e9RS2r\nf1QzU1uCw7OZuWfRlVgWEXHM5VXHZTUel1c9l9V4XF712r6s7KqQJEnVDA6SJKlaW4LDwUVXYMm4\nvOq5rMbj8qrnshqPy6teq5dVK04AJUmSlkNbWhwkSdISWHhwiIibI+LZiNiIiHsWXZ9Fi4hdEfFE\nRByPiG9HxIdL+aURcSQiTpTbS0p5RMT9Zfk9HRHXL/YTzF9EXBAR34iIL5XpqyPiqbKsPl8uCU9E\nXFSmN8rjVy2y3osQEdsj4rGI+G5Zx37BdWuwiPh35Xv4TEQ8EhEXu351RMSnI+JMRDzTUzb2uhQR\n+8v8JyJif9N7rYIBy+s/le/i0xHxxYjY3vPYvWV5PRsRv9xTvvB95kKDQ0RcAPwXOpfsfjvwgYh4\n+yLr1AIvA7+WmW8D9gIfKsvkHuBoZu4GjpZp6Cy73eXvAPDA/Ku8cB8GjvdMfwK4ryyrF4C7S/nd\nwAuZ+RbgvjLfuvkk8OXM/FngHXSWm+tWg4jYAfxbYE9m/hxwAXAHrl9dn6FzMcNeY61LEXEp8HHg\nncANwMe7YWMFfYbzl9cR4Ocy8+eBPwPuBSjb/DuAf1ye81/LD6RW7DMX3eJwA7CRmd/PzB8DnwP2\nLbhOC5WZpzPz6+X+X9PZsO+gs1wOldkOAbeV+/uAh7PjSWB7RFw552ovTETsBH4FeLBMB3Aj8FiZ\npX9ZdZfhY8BNZf61EBFvBP4Z8BBAZv44M1/EdWuYbcBPRcQ24PXAaVy/AMjMPwbO9hWPuy79MnAk\nM89m5gt0dqT9O9eV0LS8MvMPM/PlMvkksLPc3wd8LjN/lJl/DmzQ2V+2Yp+56OCwg87lurs2S5mA\n0tR5HfAUcEVmnoZOuAAuL7Ot+zL8LeDXgZ+U6cuAF3u+jL3L45VlVR4/V+ZfF9cAPwB+u3TtPBgR\nb8B1q1Fm/iXwn4Hn6ASGc8DXcP0aZtx1aa3XsT7/Cvhf5X6rl9eig0NTGvcwDyAifhr4PeAjmfnD\nYbM2lK3FMoyI9wJnMvNrvcUNs2bFY+tgG3A98EBmXgf8La82JTdZ6+VVmsz3AVcD/xB4A50m4n6u\nX6MNWjYuMyAiPkanm/qz3aKG2VqzvBYdHDaBXT3TO4FTC6pLa0TE6+iEhs9m5hdK8fPdZuJye6aU\nr/MyfBfwvoj4CzpNdjfSaYHYXpqW4bXL45VlVR5/E+c3ta6yTWAzM58q04/RCRKuW81+CfjzzPxB\nZv4d8AXgn+L6Ncy469K6r2OUAaHvBT6Yr54fodXLa9HB4avA7jJK+UI6g0EOL7hOC1X6RB8Cjmfm\nb/Y8dBjojjjeDzzeU35nGbW8FzjXbSpcdZl5b2buzMyr6Kw7X8nMDwJPAO8vs/Uvq+4yfH+Zf21+\n3WTmXwEnI+Ktpegm4Du4bg3yHLA3Il5fvpfd5eX6Ndi469IfAO+JiEtKC897StlaiIibgY8C78vM\nl3oeOgzcUY7UuZrOoNI/oS37zMxc6B9wK53RpN8DPrbo+iz6D/hFOk1PTwPfLH+30ukrPQqcKLeX\nlvmDzijb7wHfojMCfOGfYwHL7d3Al8r9a+h8yTaA/wFcVMovLtMb5fFrFl3vBSyna4FjZf36feAS\n162hy+s3gO8CzwC/A1zk+vXKsnmEztiPv6PzS/juSdYlOn37G+XvrkV/rjkvrw06Yxa62/r/1jP/\nx8ryeha4pad84ftMzxwpSZKqLbqrQpIkLRGDgyRJqmZwkCRJ1QwOkiSpmsFBkiRVMzhIkqRqBgdJ\nklTN4CBJkqr9fzZq5jZbFvPQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24c5a4518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mtx,dist = calibrate()\n",
    "white_output = 'output_videos/project_video1.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\").subclip(41,42)\n",
    "white_clip = clip1.fl_image(process_image) \n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
