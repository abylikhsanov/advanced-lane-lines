{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the road lanes using OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, as images tend to be distorted, I will use the OpenCV library to calibrate and undistort the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob # To import all the calibration images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calibrate(objpoints,imgpoints):\n",
    "\n",
    "    objp = np.zeros((6*9,3), np.float32) \n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('/Users/abylikhsanov1/AI/carnd/term1/advanced-lane-lines/camera_cal/calibration*.jpg') # Please update if needed\n",
    "    for fname in images:\n",
    "        image = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None) # Finding any distorted pixel locations\n",
    "        if ret is True: # If we found any, we shall append the coordinates and the pixels itself\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            cv2.drawChessboardCorners(image, (9,6), corners, ret)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we finished to get the distorted points from the sample images, we know our image points (pixels) which need to be undistorted and the constant object points (coordinates) as our final goal location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    %matplotlib inline\n",
    "    #img = cv2.imread('test_images/straight_lines1.jpg') # Now, let's undistort our first road image\n",
    "    #img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    fig,(ax1) = plt.subplots(1,1,figsize=(10,5))\n",
    "    ax1.imshow(img)\n",
    "    # Calibrating and removing the distortion\n",
    "    img_size = (img.shape[1],img.shape[0]) # We are making img_size[0] as x axis values and [1] as y axis\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints,img_size,None,None) # Calibration, moving imgpoints towards the coordinate\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(dst)\n",
    "    ax2.set_title('Undistorted Image', fontsize=30)\n",
    "    global count\n",
    "    global left_fit\n",
    "    global right_fit\n",
    "    combined_binary = gradient(dst)\n",
    "    warped,M = warp(combined_binary)\n",
    "    if(count == 0):\n",
    "        result,left_fitx,right_fitx,ploty,left_fit,right_fit = fit1(warped)\n",
    "    elif(count > 0):\n",
    "        result,left_fitx,right_fitx,ploty = fit2(warped,left_fit,right_fit)\n",
    "    final = unwarp(result,img,left_fitx,right_fitx,ploty,M)\n",
    "    count = count + 1\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After our image undistortion, the next step will be to detect the gradients of the image using the Sobel operator. We will actually create 3 methods and choose one of them toidentify pixels where the gradient of an image falls within a specified threshold range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Full code, consists of 3 methods, the Sobel (x or y), the magniture (x and y combined) and the direction (the angle of the gradient)\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Calculates the directional gradient\n",
    "    # Apply threshold\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(img,cv2.CV_64F,1,0)\n",
    "    elif orient == 'y':\n",
    "        sobel = cv2.Sobel(img,cv2.CV_64F,0,1)\n",
    "    sobel_abs = np.absolute(sobel)\n",
    "    sobel_bin = np.uint8((255*sobel_abs/np.max(sobel_abs)))\n",
    "    grad_binary = np.zeros_like(sobel_bin)\n",
    "    grad_binary[(sobel_bin>=thresh[0])&(sobel_bin<=thresh[1])] = 1\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Calculates the gradient magnitude\n",
    "    # Apply threshold\n",
    "    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0)\n",
    "    sobely = cv2.Sobel(img,cv2.CV_64F,0,1)\n",
    "    sobel_abs = np.absolute(sobelx+sobely)\n",
    "    sobel_bin = np.uint8((255*sobel_abs/np.max(sobel_abs)))\n",
    "    mag_binary = np.zeros_like(sobel_bin)\n",
    "    mag_binary[(sobel_bin>=thresh[0])&(sobel_bin<=thresh[1])] = 1\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Calculates the gradient direction\n",
    "    # Apply threshold\n",
    "    sobelx = np.absolute(cv2.Sobel(img,cv2.CV_64F,1,0))\n",
    "    sobely = np.absolute(cv2.Sobel(img,cv2.CV_64F,0,1))\n",
    "    sobel_arctan = np.uint(np.arctan(sobely,sobelx))\n",
    "    dir_binary = np.zeros_like(sobel_arctan)\n",
    "    dir_binary[(sobel_arctan>=thresh[0])&(sobel_arctan<=thresh[1])] = 1\n",
    "    return dir_binary\n",
    "\n",
    "k_size = 7 # To make our image smoother, I have concluded, that this Kernel size is optimal.\n",
    "\n",
    "#### IGNORE THE BELOW CODE IN THIS CELL, IT IS FOR THE TEST MODE ONLY ####\n",
    "\n",
    "#gradx = abs_sobel_thresh(gray, orient='x', sobel_kernel=k_size, thresh=(10, 240))\n",
    "#grady = abs_sobel_thresh(gray, orient='y', sobel_kernel=k_size, thresh=(30, 100))\n",
    "#mag_binary = mag_thresh(gray, sobel_kernel=k_size, mag_thresh=(30, 100))\n",
    "#dir_binary = dir_threshold(gray, sobel_kernel=k_size, thresh=(0.3, 1.3))\n",
    "\n",
    "#combined = np.zeros_like(dir_binary)\n",
    "#combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "\n",
    "#plt.imshow(combined,cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "#hls = cv2.cvtColor(dst,cv2.COLOR_RGB2HLS)\n",
    "#f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,10))\n",
    "#ax1.set_title('Image in grayscale, H space')\n",
    "#ax1.imshow(hls[:,:,0], cmap='gray')\n",
    "#ax2.set_title('Image in grayscale, L space')\n",
    "#ax2.imshow(hls[:,:,1], cmap='gray')\n",
    "#ax3.set_title('Image in grayscale, S space')\n",
    "#ax3.imshow(hls[:,:,2], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have defined our methods, we can experiment, which of them will work best with our image. We want to identify the line lanes. More over, in the next code cell, I will transform the image to HLS space, as you will see next, the \"Saturation\" value will make the non-white lanes more enhanced and actually performs good on shadows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(dst):\n",
    "    ## 1\n",
    "    hls = cv2.cvtColor(dst,cv2.COLOR_RGB2HLS)\n",
    "    gray = cv2.cvtColor(dst,cv2.COLOR_RGB2GRAY)\n",
    "    luv = cv2.cvtColor(dst,cv2.COLOR_RGB2LUV)\n",
    "    r = (230,255)\n",
    "    g = (230,255)\n",
    "    s = (10,200)\n",
    "    l = (1,120)\n",
    "    #r = (240,255)\n",
    "    #g = (240,255)\n",
    "    #s = (30,255)\n",
    "    #l = (30,200)\n",
    "\n",
    "    r_mag = abs_sobel_thresh(dst[:,:,0],sobel_kernel=3,thresh=r)\n",
    "    g_mag = abs_sobel_thresh(dst[:,:,1],sobel_kernel=3,thresh=g)\n",
    "    s_mag = abs_sobel_thresh(hls[:,:,2],sobel_kernel=9,thresh=s)\n",
    "    l_mag = mag_thresh(luv[:,:,0],sobel_kernel=9,thresh=l)\n",
    "    combined_binary = np.zeros_like(r_mag)\n",
    "    combined_binary[((r_mag==1) & (g_mag==1)) | (s_mag==1)] = 1\n",
    "    \n",
    "    if len(combined_binary.shape) > 2:\n",
    "        channel_count = combined_binary.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    vertices = np.int32([[[190,700],[560,450],[800,450],[1200,700]]])\n",
    "    mask = np.zeros_like(combined_binary)\n",
    "    cv2.fillPoly(mask, vertices,ignore_mask_color)\n",
    "    combined_binary = cv2.bitwise_and(combined_binary, mask)\n",
    "    \n",
    "    \n",
    "    ## 2\n",
    "    #s_mag = abs_sobel_thresh(hls[:,:,2],sobel_kernel=17,thresh=(40, 200))\n",
    "    #l_mag = abs_sobel_thresh(hls[:,:,1],orient='x',sobel_kernel=17,thresh=(120, 150))\n",
    "    #gray_mag = abs_sobel_thresh(hls[:,:,0],orient='x',sobel_kernel=17,thresh=(200,230))\n",
    "    \n",
    "    #combined_binary = np.zeros_like(gray_mag)\n",
    "    #combined_binary[(s_mag==1) | (l_mag==1) | (gray_mag==1)] = 1\n",
    "    #gray = cv2.cvtColor(dst,cv2.COLOR_RGB2GRAY)\n",
    "    #hls = cv2.cvtColor(dst,cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Sobel X on gray:\n",
    "    #sobel_gray = abs_sobel_thresh(gray, orient='x', sobel_kernel=k_size, thresh=(20, 200))\n",
    "\n",
    "    # Sobel X on S (HLS):\n",
    "    #sobel_s = abs_sobel_thresh(hls[:,:,2], orient='x', sobel_kernel=k_size, thresh=(180, 255))\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "    #combined_binary = np.zeros_like(sobel_gray)\n",
    "    #combined_binary[(sobel_s == 1) | (sobel_gray == 1)] = 1\n",
    "\n",
    "    # Plotting thresholded images\n",
    "    fig,(ax1,ax2,ax3,ax4) = plt.subplots(1,4,figsize=(20,10))\n",
    "    ax1.imshow(dst[:,:,0])\n",
    "    ax2.imshow(dst[:,:,1])\n",
    "    ax3.imshow(hls[:,:,2])\n",
    "    ax4.imshow(luv[:,:,0])\n",
    "\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, having a very good and enhanced lane lines, I will warp the image, in order to visualise the lanes in the right perspective (left and right lines have to be parallel). After warping the image (viewing from the top), the next task will be to construct the polynomial based on the line lanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Time to warp the image\n",
    "def warp(combined_binary):\n",
    "    img_size = (combined_binary.shape[1],combined_binary.shape[0])\n",
    "    #src = np.float32([[207,720],[570,468],[714,468],[1106,720]])\n",
    "    bottom_left = [320,720] \n",
    "    bottom_right = [980, 720]\n",
    "    top_left = [320, 0]\n",
    "    top_right = [980, 0]\n",
    "    src = np.float32([[261,720],[559,475],[713,475],[1200,720]])\n",
    "    #np.float32([[261,720],[559,475],[713,475],[1200,720]])\n",
    "    #np.float32([[261,720],[559,475],[713,475],[1200,720]])\n",
    "    #np.float32([[256,688],[544,492],[752,492],[1044,688]])\n",
    "    dest = np.float32([bottom_left,top_left,top_right,bottom_right])\n",
    "    M = cv2.getPerspectiveTransform(src,dest)\n",
    "    warped = cv2.warpPerspective(combined_binary,M,img_size)\n",
    "# Plotting warped and non images\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.set_title('Combined S channel and gradient thresholds')\n",
    "    ax1.imshow(combined_binary,cmap='gray')\n",
    "\n",
    "    ax2.set_title('Warped image')\n",
    "    ax2.imshow(warped, cmap='gray')\n",
    "    return warped,M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to construct the polynomial across the lane lines, I will start by finding the most dense x axis pixel values. The function below explains how the x axis points are found and based on that, the best polynomial fit is being drawn, which effectively are the lane lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit1(warped):\n",
    "    # Viewing the most dense pixel region (sum of 1 on the X scale)\n",
    "    histogram = np.sum(warped[int(warped.shape[0]/2):,:],axis=0)\n",
    "    #plt.plot(histogram)\n",
    "    out_img = warped\n",
    "\n",
    "    #In order to fit the polynomial for the lines, I will divide the image by 2 on x axis, to seperate left and right lanes\n",
    "    midpoint = int(histogram.shape[0]/2)\n",
    "    left_side = np.argmax(histogram[:midpoint]) # Getting the most dense pixel region at x axis, argmax returns the index\n",
    "    right_side = np.argmax(histogram[midpoint:]) + midpoint # Getting the most dense pixel region at x axis right side\n",
    "# As the maximum Y value is 720, I will choose to divide it to 9 windows\n",
    "    windows = 9\n",
    "\n",
    "# Set height of windows\n",
    "    window_height = np.int(warped.shape[0]/windows) # In this code, this is int size of 80 (80 pixels)\n",
    "\n",
    "# Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = warped.nonzero() # Pixel locations where pixel is 1, [1] = x, [0] = y\n",
    "    nonzeroy = np.array(nonzero[0]) \n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "# Current positions to be updated for each window\n",
    "    leftx_current = left_side \n",
    "    rightx_current = right_side\n",
    "\n",
    "# Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "# Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "# Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0])# All Y values\n",
    "    \n",
    "\n",
    "# Step through the windows one by one (Search only for the first frame)\n",
    "    for window in range(windows): # Looping in 9 steps\n",
    "    # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = warped.shape[0] - (window+1)*window_height # Loop 1, 0+1 * 80 = 80 px\n",
    "        win_y_high = warped.shape[0] - window*window_height # Loop 1, 0 px, this is a top value, as y values are from the top to the bottom\n",
    "        win_xleft_low = left_side - margin # Setting the square boundaries, from the current found lane piece\n",
    "        win_xleft_high = left_side + margin\n",
    "        win_xright_low = right_side - margin\n",
    "        win_xright_high = right_side + margin\n",
    "    # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
    "        (0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
    "        (0,255,0), 2) \n",
    "    # Identify the nonzero pixels in x and y within the window\n",
    "        left_nzero_values = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "         (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]  # Getting the pixel locations, where pixel>1\n",
    "        right_nzero_values = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "    # Append these indices to the lists\n",
    "        left_lane_inds.append(left_nzero_values) # Left_lane_inds is the list of pixel locations in that margin box\n",
    "        right_lane_inds.append(right_nzero_values)\n",
    "    # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(left_nzero_values) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[left_nzero_values])) # Enhance: Try to get the argmax of np.sum of the location\n",
    "        if right_nzero_values.size > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[right_nzero_values])) # For all the x values with pixels>1, we get the mean of that\n",
    "\n",
    "\n",
    "# Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "# Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds] # Get the\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "# Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    out_img = np.dstack((warped, warped, warped))*255\n",
    "    window_img = np.zeros_like(out_img) # Getting the blank image to display the curves\n",
    "# Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0] ) # All the y values\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "# Generate a polygon to illustrate the search window area\n",
    "# And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+(right_fitx-left_fitx),ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    return result,left_fitx,right_fitx,ploty,left_fit,right_fit\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit2(warped,left_fit,right_fit):\n",
    "    margin = 100\n",
    "# Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "# Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0])# All Y values\n",
    "    out_img = warped\n",
    "    nonzero = warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "    left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "    right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "# Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "# Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "# Generate x and y values for plotting\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        \n",
    "    out_img = np.dstack((warped, warped, warped))*255\n",
    "    window_img = np.zeros_like(out_img) # Getting the blank image to display the curves\n",
    "# Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "# Generate a polygon to illustrate the search window area\n",
    "# And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+(right_fitx-left_fitx),ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    return result,left_fitx,right_fitx,ploty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the polynomials, the next step is to unwarp them into the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unwarp(result,image,left_fitx,right_fitx,ploty,M):\n",
    "    # Create an image to draw the lines on\n",
    "    #warp_zero = np.zeros_like(result).astype(np.uint8)\n",
    "    #color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    warp_zero = np.zeros_like(image)\n",
    "    #color_warp = np.dstack((result, result, result))*255\n",
    "\n",
    "# Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    bottom_left = [left_fitx[0],result.shape[0]] \n",
    "    bottom_right = [right_fitx[0], result.shape[0]]\n",
    "    top_left = [left_fitx[-1], 0]\n",
    "    top_right = [right_fitx[-1], 0]\n",
    "    #pts = np.array([bottom_left,bottom_right,top_left,top_right])\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(warp_zero, np.int_([pts]), (0,255,0))\n",
    "    src = np.float32([bottom_left,top_left,top_right,bottom_right])\n",
    "    dest = np.float32([[261,720],[559,475],[713,475],[1200,720]])\n",
    "    #np.float32([[261,720],[559,475],[713,475],[1200,720]])\n",
    "    #np.float32([[261,720],[559,475],[713,475],[1200,720]])\n",
    "    #np.float32([[256,688],[544,492],[752,492],[1044,688]])\n",
    "    M_inv = cv2.getPerspectiveTransform(src,dest)\n",
    "\n",
    "# Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(warp_zero, M_inv, (image.shape[1], image.shape[0])) \n",
    "# Combine the result with the original image\n",
    "\n",
    "    final = cv2.addWeighted(image, 1, newwarp, 0.3, 0)\n",
    "    fig,(ax1) = plt.subplots(1,1,figsize=(15,5))\n",
    "    ax1.imshow(final)\n",
    "    \n",
    "    \n",
    "    #bottom_left = [left_fitx[0],result.shape[0]] \n",
    "    #bottom_right = [right_fitx[0], result.shape[0]]\n",
    "    #top_left = [left_fitx[-1], 0]\n",
    "    #top_right = [right_fitx[-1], 0]\n",
    "    #dest = np.float32([[207,720],[570,468],[714,468],[1106,720]])\n",
    "    ##dest = np.float32([[256,688],[544,492],[752,492],[1044,688]])\n",
    "    #src = np.float32([bottom_left,top_left,top_right,bottom_right])\n",
    "    #img_size = (img.shape[1],img.shape[0])\n",
    "    #M = cv2.getPerspectiveTransform(src,dest)\n",
    "    #result_unwarp = cv2.warpPerspective(result,M,img_size)\n",
    "# Plotting warped and non images\n",
    "    #if len(img.shape) > 2:\n",
    "     #   channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "      #  ignore_mask_color = (255,) * channel_count\n",
    "    #else:\n",
    "     #   ignore_mask_color = 255\n",
    "\n",
    "    #mask = np.zeros_like(result)\n",
    "    #vertices = np.array([[[256,688],[544,492],[752,492],[1100,688]]],dtype=np.int32)\n",
    "    #cv2.fillPoly(mask, vertices,ignore_mask_color)\n",
    "    ###returning the image only where mask pixels are nonzero\n",
    "    #masked_image = cv2.bitwise_and(result_unwarp, mask)\n",
    "    #final = cv2.addWeighted(img, 1, masked_image, 1, 1)\n",
    "    #f, (ax1) = plt.subplots(1, 1, figsize=(20,10))\n",
    "\n",
    "    #ax1.set_title('Warped image')\n",
    "    #ax1.imshow(final)\n",
    "    return final\n",
    "    #cv2.imwrite( \"output_images/straight_lines1.jpg\", cv2.cvtColor(final,cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_videos/project_video.mp4\n",
      "[MoviePy] Writing video output_videos/project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n",
      " 62%|██████▏   | 16/26 [00:19<00:11,  1.17s/it]"
     ]
    }
   ],
   "source": [
    "white_output = 'output_videos/project_video.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\").subclip(0,1)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "count = 0\n",
    "left_fit = np.array([0,0,0], dtype='float')\n",
    "right_fit = np.array([0,0,0], dtype='float')\n",
    "calibrate(objpoints,imgpoints)\n",
    "white_clip = clip1.fl_image(process_image) \n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "print(\"The number is: \",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self,first=True,recent_xfitted=[],bestx=None,best_fit=None,current_fit=[np.array([False])],\n",
    "                 radius_of_curvature = None,\n",
    "                 line_base_pos = None,diffs = np.array([0,0,0], dtype='float'),allx = None,ally=None):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.first = first\n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = recent_xfitted\n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = bestx\n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = best_fit\n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = current_fit\n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = radius_of_curvature\n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = line_base_pos\n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = diffs\n",
    "        #x values for detected line pixels\n",
    "        self.allx = allx\n",
    "        #y values for detected line pixels\n",
    "        self.ally = ally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
